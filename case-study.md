# Case-study оптимизации

## Актуальная проблема
Необходимо обработать файл с данными, больше ста двадцати мегабайт.

На старте уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала бесконечно долго.

Было решено исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли изменения программы положительный эффект на быстродействие программы принято решение использовать такую метрику: *время выполнения программы*

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы поставлена задача выстроить эффективный `feedback-loop`, который позволит получать обратную связь по эффективности сделанных изменений за *финальное время после оптимизации*

Для построения фидбек-лупа возьмём объём данных в размере 1000 срок

Оценка ассимптотики при отключенном garbage collector (ruby benchmark_task.rb)
```table
size       1X      2X      3X      4X      5X  (1000 строк) 
time      0.35    1.07    2.01    3.24    4.81 (секунд)
delta     0.35    0.72    0.94    1.23    1.57 (секунд/1000строк)
accel      1      1.06    0.63    0.82    0.97 (доля=секунд/1000строк^2)
```
mean(delta) ~ 96% 

mean(acceleration) ~ 90% 

Оценка продолжительности обработки полного объёма данных для исходной версии программы
```equation
3250940 / 1000 * mean(delta) ~ 52 минуты
```
Вот как выглядит `feedback_loop`: 
1. Profile `ruby-prof`: `ruby task.rb`
2. Modify code
3. Test: `ruby test-task.rb`
4. Benchmark: `ruby benchmark_task.rb`
5. Add case-study
6. Commit

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации воспользуемся 
* gem benchmark
* профилировщик `ruby-prof`

Вот какие проблемы удалось найти и решить

### Шаг №1
- отчёт `ruby_prof_reports/flat0.txt`  показал главную "точку роста"
```table
 44.93      1.442     1.442     0.000     0.000      154   Array#select   
```
- в качестве оптимизации принято решение поменять `sessions = Array` на `Hash` с ключами по `user_id`
- метрика `1X` уменьшилась до `0.15`
- в итоге в отчёте профилировщика "точка роста" `Array#select` исчезла 

### Шаг №2
- отчёт `ruby_prof_reports/flat1.txt`  показал главную "точку роста"
```table
 51.95      0.880     0.878     0.000     0.002     1000   Array#all?
```
- в качестве оптимизации принято решение переписать конструктор `uniqueBrowsers`
- метрика `1X` уменьшилась до `0.1`
- в итоге в отчёте профилировщика "точка роста" `Array#all?` исчезла 

### Шаг №3
- отчёт `ruby_prof_reports/flat2.txt`  показал две относительно равнозначные главные "точки роста"
```table
 27.36      0.817     0.227     0.000     0.589       10   Array#each
 21.76      0.408     0.181     0.000     0.227     1695   Array#map                      
```
- в качестве оптимизации принято решение внести все очевидные оптимизации внутри циклов each
- метрика `1X` уменьшилась до `0.08`
- в итоге в отчёте профилировщика `ruby_prof_reports/flat3.txt`  "точка роста" `Array#each`уменьшились незначительно 
```table
 25.71      0.752     0.196     0.000     0.556        4   Array#each                     
```
  а  "точка роста" `Array#map` сократилась приблизительно в 2 раза
```table
 12.64      0.326     0.096     0.000     0.230      770   Array#map                      
```

### Шаг №4
- перешли на размер данных  `5X`
- отчёт `ruby_prof_reports/flat_5X.txt`  показал главную "точку роста"
```table
 24.76      1.046     0.262     0.000     0.785        4   Array#each                     
```
- в качестве оптимизации принято решение удалить массив и его конструктор `users_objects`, а также переписать алгоритм чтения данных из файла
- метрика `5X` уменьшилась до `0.44`
- в итоге в отчёте профилировщика "точка роста" `Array#each` уменьшилась на 10% при удалении users_objects и ещё сократилась в три раза при переносе функций парсинга данных в блок File.open, однако появилась  "точка роста" IO#each
```table
 20.29      0.344     0.183     0.000     0.161        1   IO#each
```
- При подготовке отчёта профилировщик `ruby-prof` самопроизвольно стал тормозить выполнение программы. Поэтому его следующие показания в `ruby_prof_reports/flat4.txt`  будут в три раза выше ранее зафиксированных, но не сохранённых  
```table
 19.86      1.169     0.622     0.000     0.548        1   IO#each                        
```

### Шаг №5
- отчёт `ruby_prof_reports/flat4.txt`  показывает две проблемные "точки роста", на которых сосредоточимся
```table
 14.97      0.925     0.469     0.000     0.456     4226   <Class::Date>#parse            
 11.70      1.352     0.366     0.000     0.985     3870   Array#map                      
```
- в качестве оптимизации принято решение перенести парсинг дат в блок чтения данных
- метрика `5X` не уменьшилась
- в итоге модернизации программы в отчёте профилировщика "точка роста" лишь поменяла своего родителя

## Результаты
В результате проделанной оптимизации удалось ускорить вычисления при отключенном garbage collector ориенировочно в 10 раз. На данных work(filename = 'data_5X.txt', disable_gc: false) работает 0.49 сек.
При включённом garbage collector фактическое ускорение составляет только 5 раз.
Общее время обработки 128 мб данных после оптимизации занял 39 минут (2354.71 сек.).
Результитующий json-файл получился 138 мб


## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы были добавлены RSpec-тесты `assert-performance.rb`

